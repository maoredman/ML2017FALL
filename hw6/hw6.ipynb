{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, concatenate, Input, Reshape, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.models import load_model\n",
    "import csv\n",
    "import os\n",
    "import errno\n",
    "import operator\n",
    "import sys\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import random\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clustering images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = np.load('data/image.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,100):\n",
    "    img = Image.fromarray(images[i].reshape(28,28))\n",
    "    img.save('data/image_output/{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=700, random_state=None,\n",
       "  svd_solver='arpack', tol=0.0, whiten=True)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=700, whiten=True, svd_solver='arpack')\n",
    "pca.fit(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 784)\n"
     ]
    }
   ],
   "source": [
    "print(pca.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pca.components_)):\n",
    "    img = Image.fromarray((pca.components_[i]*30).astype('uint8').reshape(28,28)) # amplified pixel strength\n",
    "    img.save('data/eigen_images/{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_images = pca.transform(images)\n",
    "reconstructed_images = pca.inverse_transform(pca_images) # with n_components = 784, looks the same to me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 700)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image.fromarray(reconstructed_images[6].reshape(28,28)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=40, init='random', random_state=0, max_iter=20).fit(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 784)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(nmf.components_)):\n",
    "    img = Image.fromarray(pca.components_[i].astype('uint8').reshape(28,28))\n",
    "    img.save('data/nmf_images/{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering: K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, init='k-means++', max_iter=300,\n",
    "                tol=0.0001, precompute_distances='auto', verbose=0,\n",
    "                random_state=None, copy_x=True, n_jobs=1, algorithm='auto').fit(pca_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for idx in range(0,100):\\n    print(idx, kmeans.labels_[idx])'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx in range(0,100):\n",
    "    print(idx, kmeans.labels_[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140000"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('labels.pickle', 'wb') as handle:\n",
    "    pickle.dump(kmeans.labels_, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rule-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"rule_predictions = [] # 1 for MNIST, 0 for fashionMNIST\\ncount = 0\\n\\nfor idx, image in enumerate(images): # estimate 3 minutes\\n    if idx % 5000 == 0:\\n        print('finished processing', idx/len(images))\\n        \\n    pixel_count = 0\\n    non_black_count = 0\\n    near_white_count = 0\\n    \\n    for pixel in image:\\n        pixel_count += 1\\n        if pixel > 0:\\n            non_black_count += 1\\n            if pixel > 200:\\n                near_white_count += 1\\n                \\n    # if near_white_count / non_black_count > 0.5:\\n    if non_black_count / pixel_count > 0.3:\\n        # predictions.append(1)\\n        rule_predictions.append(0)\\n    else:\\n        # predictions.append(0)\\n        rule_predictions.append(1)\\n    count += 1\\nprint('finished generating rule_predictions!')\""
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_predictions = [] # 1 for MNIST, 0 for fashionMNIST\n",
    "count = 0\n",
    "\n",
    "for idx, image in enumerate(images): # estimate 3 minutes\n",
    "    if idx % 5000 == 0:\n",
    "        print('finished processing', idx/len(images))\n",
    "        \n",
    "    pixel_count = 0\n",
    "    non_black_count = 0\n",
    "    near_white_count = 0\n",
    "    \n",
    "    for pixel in image:\n",
    "        pixel_count += 1\n",
    "        if pixel > 0:\n",
    "            non_black_count += 1\n",
    "            if pixel > 200:\n",
    "                near_white_count += 1\n",
    "                \n",
    "    # if near_white_count / non_black_count > 0.5:\n",
    "    if non_black_count / pixel_count > 0.3:\n",
    "        # predictions.append(1)\n",
    "        rule_predictions.append(0)\n",
    "    else:\n",
    "        # predictions.append(0)\n",
    "        rule_predictions.append(1)\n",
    "    count += 1\n",
    "print('finished generating rule_predictions!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i in range(100):\\n    print(i, rule_predictions[i])'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(i, rule_predictions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished reading file\n"
     ]
    }
   ],
   "source": [
    "x_submission = []\n",
    "\n",
    "with open('data/test_case.csv', 'rt') as testfile:\n",
    "    reader = csv.reader(testfile, delimiter=',')\n",
    "    next(reader) # skip headings\n",
    "    for row in reader:\n",
    "        # print([int(row[1]), int(row[2])])\n",
    "        x_submission.append([int(row[1]), int(row[2])])\n",
    "print('finished reading file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980000"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[68922, 34890]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_submission[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980000\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for id_pair in x_submission:\n",
    "    if kmeans.labels_[id_pair[0]] == kmeans.labels_[id_pair[1]]:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rule-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980000\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for id_pair in x_submission:\n",
    "    if rule_predictions[id_pair[0]] == rule_predictions[id_pair[1]]:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished writing submission!\n"
     ]
    }
   ],
   "source": [
    "with open('nonblack_0.3.csv', 'wt') as outfile:\n",
    "    test_writer = csv.writer(outfile)\n",
    "    test_writer.writerow(['ID','Ans'])\n",
    "    \n",
    "    counter = 0\n",
    "    for i in predictions:\n",
    "        test_writer.writerow([counter, int(i)])\n",
    "        counter += 1\n",
    "    \n",
    "print('finished writing submission!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
