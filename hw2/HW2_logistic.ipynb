{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 請手刻gradient descent實作logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### read X_train and Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# 106 columns\n",
    "\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "with open('data/X_train.csv', 'rt', encoding='big5') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    row1 = next(reader) # skip headings\n",
    "    for idx, row in enumerate(reader):\n",
    "        X_train.append([float(i) for i in row] + [1.0])\n",
    "        \n",
    "        '''continuous_idxs = []\n",
    "        for idx2, num in enumerate(row):\n",
    "            if float(num) > 1:\n",
    "                continuous_idxs.append(idx2)\n",
    "        print(continuous_idxs)'''\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "for col in [0,1,3,4,5]: # [0,1,3,4,5] only, shouldn't normalize one-hot columns, will be affected by data\n",
    "    if np.std(X_train[:,col]) != 0:\n",
    "        X_train[:,col] = np.divide((X_train[:,col] - np.average(X_train[:,col])), np.std(X_train[:,col]))\n",
    "\n",
    "# [[data1]\n",
    "#  [data2]]\n",
    "\n",
    "with open('data/Y_train.csv', 'rt', encoding='big5') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    row1 = next(reader) # skip headings\n",
    "    for idx, row in enumerate(reader):\n",
    "        Y_train.append(float(row[0]))\n",
    "\n",
    "Y_train = np.array(Y_train)\n",
    "# [y1 y2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(len(X_train[0]))\\n# print(X_train[0:2])\\n# print(X_train[0:3])\\nprint(X_train[7])\\nprint(Y_train[7])'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''print(len(X_train[0]))\n",
    "# print(X_train[0:2])\n",
    "# print(X_train[0:3])\n",
    "print(X_train[7])\n",
    "print(Y_train[7])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### define sigmoid function for numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x): # this sigmoid works with numpy arrays\n",
    "    res =  1.0 / (1 + np.exp(-x))\n",
    "    return np.clip(res, 0.00000000000001, 0.99999999999999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### start training, split X_train into X_real_train and X_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### currently not caring about validation set, directly train with X_real_train = X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### accuracy stuck at 0.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 training accuracy 0.827824484625\n",
      "1 validation accuracy 0.837223587224\n",
      "2 training accuracy 0.83028139276\n",
      "2 validation accuracy 0.839987714988\n",
      "3 training accuracy 0.845291565895\n",
      "3 validation accuracy 0.854269041769\n",
      "4 training accuracy 0.840224192867\n",
      "4 validation accuracy 0.846744471744\n",
      "5 training accuracy 0.831740181965\n",
      "5 validation accuracy 0.836916461916\n",
      "6 training accuracy 0.848285922684\n",
      "6 validation accuracy 0.858722358722\n",
      "7 training accuracy 0.835809436063\n",
      "7 validation accuracy 0.84398034398\n",
      "8 training accuracy 0.846328074014\n",
      "8 validation accuracy 0.855958230958\n",
      "9 training accuracy 0.84678874429\n",
      "9 validation accuracy 0.854422604423\n",
      "10 training accuracy 0.846251295635\n",
      "10 validation accuracy 0.858722358722\n"
     ]
    }
   ],
   "source": [
    "# optimizations to consider when hand-crafting everything: feature scaling (done), l1 l2 norm\n",
    "\n",
    "# grab validation set\n",
    "import random\n",
    "val_idxs = random.sample(range(0, len(X_train)), int(len(X_train) * 0.2))\n",
    "X_valid = X_train[val_idxs]\n",
    "Y_valid = Y_train[val_idxs]\n",
    "\n",
    "X_real_train = np.copy(np.delete(X_train, val_idxs, 0))\n",
    "Y_real_train = np.copy(np.delete(Y_train, val_idxs, 0))\n",
    "'''X_real_train = X_train\n",
    "Y_real_train = Y_train'''\n",
    "\n",
    "# old batch = 50 #len(X_real_train)\n",
    "batch = 800 #800 seems promising\n",
    "lr = 0.01\n",
    "decay = 0.95\n",
    "my_lambda = 0 # l2 norm\n",
    "\n",
    "prev_grads = [] # for adagrad\n",
    "\n",
    "\n",
    "# initialize weights\n",
    "weights = np.zeros(len(X_train[0])) # we already appended bias to X_train\n",
    "\n",
    "#===================saving previous weights======================\n",
    "# weights = weights_saved\n",
    "\n",
    "for epoch in range(0,10):\n",
    "    # randomly decide training order in this epoch\n",
    "    # [41,6,0,231...]\n",
    "    random_idxs = random.sample(range(0, len(X_real_train)), len(X_real_train))\n",
    "    for i in range(0, len(random_idxs), batch):\n",
    "        X_batch = X_real_train[random_idxs[i: min(i+batch, len(random_idxs))]]\n",
    "        Y_batch = Y_real_train[random_idxs[i: min(i+batch, len(random_idxs))]]\n",
    "        Y_pred = np.dot(X_batch, weights)\n",
    "        Y_pred = sigmoid(Y_pred)\n",
    "        Y_pred = np.around(Y_pred)\n",
    "\n",
    "        # get gradients and update weights\n",
    "        gradient = np.zeros(len(X_train[0]))\n",
    "        for idx_batch in range(0, len(X_batch)):\n",
    "            '''if np.isnan(((Y_batch[idx_batch] - Y_pred[idx_batch]) * X_batch[idx_batch] + l2)[0]):\n",
    "                print('weights', weights)\n",
    "                print('Y_batch', Y_batch[idx_batch])\n",
    "                print('Y_pred', Y_pred[idx_batch])\n",
    "                print('X_batch', X_batch[idx_batch])\n",
    "                print('l2', l2)'''\n",
    "            l2 = 2 * my_lambda * np.append(weights[:-1],0)\n",
    "            # print('gradient adding', - ((Y_batch[idx_batch] - Y_pred[idx_batch]) * X_batch[idx_batch] + l2))\n",
    "            gradient += - ((Y_batch[idx_batch] - Y_pred[idx_batch]) * X_batch[idx_batch] + l2)\n",
    "        gradient /= batch\n",
    "        \n",
    "        ## prev_grads.append(gradient + 0.00000001) # to avoid dividing by zero using adagrad\n",
    "        # print('gradient', gradient)\n",
    "        # print('prev_grads', prev_grads)\n",
    "        ## adagrad_denom = np.sqrt(sum(np.array(prev_grads) ** 2))\n",
    "        ## new_grad = gradient / adagrad_denom\n",
    "        # print('adagrad denom', adagrad_denom)\n",
    "        # print('new grad', new_grad)\n",
    "        # print(new_lr)\n",
    "        weights = weights - lr * gradient * pow(decay, epoch)  # - lr * new_grad\n",
    "            \n",
    "    if True:\n",
    "        train_pred = np.dot(X_real_train, weights)\n",
    "        train_pred = sigmoid(train_pred)\n",
    "        train_pred = np.around(train_pred)\n",
    "        '''print(train_pred[0:20])\n",
    "        print(Y_real_train[0:20])'''\n",
    "        print(epoch+1, 'training accuracy', np.sum(train_pred == Y_real_train) / (len(Y_real_train)))\n",
    "\n",
    "        valid_pred = np.dot(X_valid, weights)\n",
    "        valid_pred = sigmoid(valid_pred)\n",
    "        valid_pred = np.around(valid_pred)\n",
    "        print(epoch+1, 'validation accuracy', np.sum(valid_pred == Y_valid) / (len(Y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# 0.82\\nweights_saved = weights\\n# print(weights_saved)\\nnp.save('weights_logistic', weights_saved)\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 0.82\n",
    "weights_saved = weights\n",
    "# print(weights_saved)\n",
    "np.save('weights_logistic', weights_saved)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.\n",
      "  0.  1.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "\n",
    "with open('data/X_test.csv', 'rt', encoding='big5') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "\n",
    "    row1 = next(reader) # skip headings\n",
    "    for row in reader:\n",
    "        X_test.append([float(i) for i in row] + [1.0])\n",
    "            \n",
    "X_test = np.array(X_test)\n",
    "for col in [0,1,3,4,5]:\n",
    "    if np.std(X_test[:,col]) != 0:\n",
    "        X_test[:,col] = np.divide((X_test[:,col] - np.average(X_test[:,col])), np.std(X_test[:,col]))\n",
    "\n",
    "pred = np.dot(X_test, weights)\n",
    "pred = sigmoid(pred)\n",
    "pred = np.around(pred)\n",
    "print(pred[0:100])\n",
    "\n",
    "with open('data/submission.csv', 'wt') as outfile:\n",
    "    test_writer = csv.writer(outfile)\n",
    "    test_writer.writerow(['id','label'])\n",
    "    \n",
    "    counter = 0\n",
    "    for num in pred:\n",
    "        counter += 1\n",
    "        test_writer.writerow([str(counter),int(num)])\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
